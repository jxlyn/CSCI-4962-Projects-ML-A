{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgfeUJa4cjBeDWNSxjIT8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jxlyn/CSCI-4962-Projects-ML-AI/blob/main/Homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I slightly modified my machine learning problem from homework 1 to make my result more accurate. The accuracy in my homework 1 is only 0.01 since we need to find a winner from 500 players which is 1/500. I changed my problem from predict whether or not a person will win a wrestling game to predict whether or not a person will be rank first 10 in a wrestling game. \n"
      ],
      "metadata": {
        "id": "F75fUHsPXLPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Task 1 (30 points): Implement a Decision Tree Classifier for your classification problem. You\n",
        "may use a built-in package to implement your classifier. Try modifying one or more of the input\n",
        "parameters and describe what changes you notice in your results. Clearly describe how these\n",
        "factors are affecting your output.**"
      ],
      "metadata": {
        "id": "dpPrb2lzaHY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from google.colab import drive\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def accuracy(X,y,model):\n",
        "  #use the formula from the lecture\n",
        "  # repeated k-fold process\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "  # report performance\n",
        "  print('Accuracy: %.3f, standard deviation is %.3f' % (mean(n_scores), std(n_scores)))\n",
        " \n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('drive/My Drive/ML and AI/Hw1/data.csv')\n",
        "\n",
        "new_data2 = data.copy()\n",
        "X = new_data2.drop([\"gender\", \"nationality\", \"federation\",\"name\",\"sports\",\"Unnamed: 0\"], axis=1)\n",
        "X = X.to_numpy()\n",
        "\n",
        "Y = new_data2.drop([\"gender\", \"nationality\", \"federation\",\"name\",\"sports\",\"Unnamed: 0\"], axis=1)\n",
        "Y = Y.pop(\"rank\").values\n",
        "\n",
        "# if the rank is first 100, set it to 1(yes)\n",
        "# if not, set it to 0 (no)\n",
        "for z in range(len(Y)):\n",
        "  if Y[z] <= 10:\n",
        "    Y[z] =1\n",
        "  else:\n",
        "    Y[z] =0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPDSvoCYaOSw",
        "outputId": "9623fe4b-e257-4d8f-f08b-60c32d7c18a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(max_depth=100, min_samples_split = 2, max_features =3)\n",
        "model = model.fit(X, Y)\n",
        "print(\"Decision tree classifier before modifying: \")\n",
        "accuracy(X,Y,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZNoGcOXVa7f",
        "outputId": "e3615fa4-0960-494e-aa9d-47a22f6bd63b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree classifier before modifying: \n",
            "Accuracy: 0.993, standard deviation is 0.011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the accuracy for decision tree classifier before modifying is very low."
      ],
      "metadata": {
        "id": "a5PJxMIgZmg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## modifying the depth \n",
        "more_depth_model = DecisionTreeClassifier(max_depth =999,min_samples_split = 2, max_features =3).fit(X,Y)\n",
        "print(\"The accuracy for decision tree classifier with more depth:\")\n",
        "accuracy(X,Y,more_depth_model)\n",
        "\n",
        "less_depth_model = DecisionTreeClassifier(max_depth =1,min_samples_split = 2, max_features =3).fit(X,Y)\n",
        "print(\"\\nThe accuracy for decision tree classifier with less depth:\")\n",
        "accuracy(X,Y,less_depth_model)"
      ],
      "metadata": {
        "id": "Z_4lSI9TaLwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecd50bb-fdbe-427d-9705-5bb019830bf2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for decision tree classifier with more depth:\n",
            "Accuracy: 0.994, standard deviation is 0.012\n",
            "\n",
            "The accuracy for decision tree classifier with less depth:\n",
            "Accuracy: 0.988, standard deviation is 0.010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see,if we increase the max_depth and keep other factors constant, the accuracy will increase. If we decrease the max_depth and keep other factors constant, the accuracy will decrease."
      ],
      "metadata": {
        "id": "CABRddpsMFvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## modifying the min_samples_split \n",
        "more_sample_model = DecisionTreeClassifier(max_depth =100,min_samples_split = 4, max_features =3).fit(X,Y)\n",
        "print(\"The accuracy for decision tree classifier with more min_samples_split:\")\n",
        "accuracy(X,Y,more_sample_model)\n",
        "\n",
        "less_sample_model = DecisionTreeClassifier(max_depth =100,min_samples_split = 0.1, max_features =3).fit(X,Y)\n",
        "print(\"\\nThe accuracy for decision tree classifier with less min_samples_split:\")\n",
        "accuracy(X,Y,less_sample_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veRyQ4k7PRZC",
        "outputId": "4931465d-f45a-4813-ffc1-4d3c4a817bd8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for decision tree classifier with more min_samples_split:\n",
            "Accuracy: 0.995, standard deviation is 0.010\n",
            "\n",
            "The accuracy for decision tree classifier with less min_samples_split:\n",
            "Accuracy: 0.991, standard deviation is 0.011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see as the min_samples_split increases, the accuracy increases. As the min_samples_split decreases, the accuracy decreases."
      ],
      "metadata": {
        "id": "i29jiH-ERGcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## modifying the max_features\n",
        "more_feature_model = DecisionTreeClassifier(max_depth =100,min_samples_split = 2, max_features =5).fit(X,Y)\n",
        "print(\"The accuracy for decision tree classifier with more max_features:\")\n",
        "accuracy(X,Y,more_feature_model)\n",
        "\n",
        "less_feature_model = DecisionTreeClassifier(max_depth =100,min_samples_split = 2, max_features =1).fit(X,Y)\n",
        "print(\"\\nThe accuracy for decision tree classifier with less max_features:\")\n",
        "accuracy(X,Y,less_feature_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOTqhIJqRtNo",
        "outputId": "bf31b36c-ce30-473e-892c-cec2559bb653"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for decision tree classifier with more max_features:\n",
            "Accuracy: 0.997, standard deviation is 0.007\n",
            "\n",
            "The accuracy for decision tree classifier with less max_features:\n",
            "Accuracy: 0.983, standard deviation is 0.016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see as the max_feature increases, the accuracy increases. As the max_feature decreases, the accuracy decreases."
      ],
      "metadata": {
        "id": "SGlNpyE3SqRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2 (30 points): From the Bagging and Boosting ensemble methods pick any one algorithm\n",
        "from each category. Implement both the algorithms using the same data. Use k-fold cross\n",
        "validation to find the effectiveness of both the models. Comment on the difference/similarity of\n",
        "the results.**"
      ],
      "metadata": {
        "id": "ON7fE3pOS-T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Implementing Random Forest\n",
        "RF_model = RandomForestClassifier(max_depth=100, min_samples_split = 2, max_features =3).fit(X,Y)\n",
        "print(\"The accuracy for random forest model:\")\n",
        "accuracy(X,Y,RF_model)\n",
        "\n",
        "#Implementing Adaboost\n",
        "Adaboost_model = AdaBoostClassifier(n_estimators=4, random_state=0, algorithm='SAMME')\n",
        "print(\"\\nThe accuracy for Adaboost model:\")\n",
        "accuracy(X,Y,Adaboost_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUnmeeknTUXw",
        "outputId": "29701866-c239-466d-942f-a9c76f1902ef"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for random forest model:\n",
            "Accuracy: 0.997, standard deviation is 0.007\n",
            "\n",
            "The accuracy for Adaboost model:\n",
            "Accuracy: 0.999, standard deviation is 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the difference between the random forest model and adaboost model is that adaboost model have higher accuracy and smaller standard deviation than random forest model. The similarity between the random forest model and adaboost model is they both are more accurate than decision tree model."
      ],
      "metadata": {
        "id": "ySUyVATZYRGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3 (40 points): Compare the effectiveness of the three models implemented above. Clearly\n",
        "describe the metric you are using for comparison. Describe (with examples) Why is this\n",
        "metric(metrics) suited/appropriate for the problem at hand? How would a choice of a different\n",
        "metric impact your results? Can you demonstrate that?**"
      ],
      "metadata": {
        "id": "L3iTbttNphKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X , test_X, train_Y, test_Y = train_test_split(X,Y,train_size =0.6,test_size=0.4,random_state =0)\n",
        "tree_model = DecisionTreeClassifier(max_depth=100, min_samples_split = 2, max_features =3).fit(train_X,train_Y)\n",
        "pred_y1 = tree_model.predict(test_X)\n",
        "print(f\"Confusion matrix for decision tree model: \\n{confusion_matrix(test_Y, pred_y1)}\")\n",
        "print(f\"Accuracy score for decision tree model: {accuracy_score(pred_y1, test_Y)}\")\n",
        "print(f\"F1 score for decision tree model: {f1_score( test_Y,pred_y1,average='weighted')}\")\n",
        "\n",
        "RF_model2 = RandomForestClassifier(max_depth=100, min_samples_split = 2, max_features =3).fit(train_X,train_Y)\n",
        "pred_y2 = RF_model2.predict(test_X)\n",
        "print(f\"\\nConfusion matrix for random forest model: \\n{confusion_matrix(test_Y, pred_y2)}\")\n",
        "print(f\"Accuracy score for random forest model: {accuracy_score(pred_y2, test_Y)}\")\n",
        "print(f\"F1 score for random forest model: {f1_score( test_Y,pred_y2,average='weighted')}\")\n",
        "\n",
        "Adaboost_model2 = AdaBoostClassifier(n_estimators=4, random_state=0, algorithm='SAMME').fit(train_X,train_Y)\n",
        "pred_y3 = Adaboost_model2.predict(test_X)\n",
        "print(f\"\\nConfusion matrix for adaboost model: \\n{confusion_matrix(test_Y, pred_y3)}\")\n",
        "print(f\"Accuracy score for adaboost model: {accuracy_score(pred_y3, test_Y)}\")\n",
        "print(f\"F1 score for adaboost model: {f1_score( test_Y,pred_y3,average='weighted') }\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J10Xr-EDvfvj",
        "outputId": "62a30383-9c4a-43aa-c507-1b2c973c6555"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix for decision tree model: \n",
            "[[191   3]\n",
            " [  4   2]]\n",
            "Accuracy score for decision tree model: 0.965\n",
            "F1 score for decision tree model: 0.9634540780556204\n",
            "\n",
            "Confusion matrix for random forest model: \n",
            "[[194   0]\n",
            " [  4   2]]\n",
            "Accuracy score for random forest model: 0.98\n",
            "F1 score for random forest model: 0.9751020408163267\n",
            "\n",
            "Confusion matrix for adaboost model: \n",
            "[[194   0]\n",
            " [  2   4]]\n",
            "Accuracy score for adaboost model: 0.99\n",
            "F1 score for adaboost model: 0.989025641025641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see among decision tree model, adaboost model, random forest model, the most accurate one is adaboost model. It has the highest accuracy and F1 score. I used confusion matrix, accuracy score, F1 score as the metic for comparison. I also used the same metric in homework 1. This is a suitable metric for predicting who will rank top 10 in a wrestling game because when predicting whether or not a person will be the top 10 players in a wrestling game, we need to consider the accuracy for each model, and F1 score. The result will be significantly affected if we pick the model with low accuracy score and F1 score. The F1 score indicates precision and recall of a classifier. If model's F1 score is closer to 1, we can conclude that the model is more accurate. When predicting who'll be the top 10 players in the wrestling game, the accuracy is extremely important, if will make player lose confidence, or being over-cofident. Also, there are people who will bet on who will win the wrestling game. By predicting the top 10 players in a wrestling game, it can help them eliminate some choices. If the prediction is inaccurate, people will lose money."
      ],
      "metadata": {
        "id": "_RPZgOqjvNPu"
      }
    }
  ]
}